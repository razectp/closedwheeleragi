# ğŸ”„ Fallback Models - Complete Guide

**Date**: 2026-02-08
**Status**: âœ… **FULLY FUNCTIONAL**

---

## ğŸ¯ Overview

O sistema de **Fallback Models** permite configurar um ou mais modelos alternativos que serÃ£o automaticamente utilizados caso o modelo primÃ¡rio demore muito para responder ou falhe.

### BenefÃ­cios

- âœ… **Maior confiabilidade**: Se um modelo estÃ¡ lento ou indisponÃ­vel, o sistema automaticamente tenta alternativas
- âœ… **Sem perda de contexto**: A memÃ³ria, tarefas e histÃ³rico de conversaÃ§Ã£o permanecem intactos
- âœ… **TransparÃªncia**: Logs indicam quando fallback foi utilizado
- âœ… **Flexibilidade**: Configure quantos modelos quiser na ordem de prioridade
- âœ… **Zero impacto na qualidade**: Todas as mensagens, tools e parÃ¢metros sÃ£o preservados

---

## âš™ï¸ ConfiguraÃ§Ã£o

### 1. ConfiguraÃ§Ã£o BÃ¡sica

Adicione no seu `.agi/config.json`:

```json
{
  "model": "gpt-4o",
  "fallback_models": ["gpt-4o-mini", "gpt-3.5-turbo"],
  "fallback_timeout": 30
}
```

**ExplicaÃ§Ã£o**:
- `model`: Modelo primÃ¡rio (sempre tentado primeiro)
- `fallback_models`: Lista de modelos alternativos na ordem de prioridade
- `fallback_timeout`: Tempo em segundos antes de desistir e tentar o prÃ³ximo modelo (padrÃ£o: 30s)

### 2. Sem Fallback (Comportamento PadrÃ£o)

Se vocÃª nÃ£o quer usar fallback, simplesmente deixe a lista vazia:

```json
{
  "model": "gpt-4o-mini",
  "fallback_models": []
}
```

O sistema funcionarÃ¡ normalmente sem tentar modelos alternativos.

---

## ğŸ“Š Exemplos de Uso

### Exemplo 1: OpenAI com Fallback

Modelo primÃ¡rio caro com fallback para modelos mais rÃ¡pidos:

```json
{
  "api_base_url": "https://api.openai.com/v1",
  "model": "gpt-4o",
  "fallback_models": ["gpt-4o-mini", "gpt-3.5-turbo"],
  "fallback_timeout": 30
}
```

**Fluxo**:
1. Tenta `gpt-4o` (30s timeout)
2. Se falhar/demorar â†’ tenta `gpt-4o-mini` (30s timeout)
3. Se falhar/demorar â†’ tenta `gpt-3.5-turbo` (30s timeout)
4. Se todos falharem â†’ retorna erro

### Exemplo 2: NVIDIA NIM com Fallback

```json
{
  "api_base_url": "https://integrate.api.nvidia.com/v1",
  "model": "meta/llama-3.3-70b-instruct",
  "fallback_models": ["meta/llama-3.1-8b-instruct", "mistralai/mistral-7b-instruct-v0.3"],
  "fallback_timeout": 45
}
```

### Exemplo 3: Anthropic Claude com Fallback OpenAI

VocÃª pode atÃ© usar provedores diferentes se tiver mÃºltiplas chaves configuradas:

```json
{
  "api_base_url": "https://api.anthropic.com/v1",
  "model": "claude-3-5-sonnet-20241022",
  "fallback_models": [],
  "fallback_timeout": 60
}
```

*Nota*: Fallback entre provedores diferentes requer que ambos usem a mesma API key ou que vocÃª configure adequadamente.

### Exemplo 4: Alta Confiabilidade (MÃºltiplos Fallbacks)

```json
{
  "model": "gpt-4o",
  "fallback_models": [
    "gpt-4o-mini",
    "gpt-3.5-turbo",
    "gpt-3.5-turbo-16k"
  ],
  "fallback_timeout": 20
}
```

Com 4 modelos configurados, vocÃª tem 3 camadas de proteÃ§Ã£o.

---

## ğŸš€ Como Funciona

### Fluxo de ExecuÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. User envia mensagem                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Tenta modelo primÃ¡rio                    â”‚
â”‚    - Timeout: fallback_timeout              â”‚
â”‚    - Mesmas messages, tools, params         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€â–º âœ… Sucesso? â†’ Retorna resposta
               â”‚
               â”œâ”€â–º âŒ Falhou/Timeout?
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Tenta fallback_models[0]                 â”‚
â”‚    - Timeout: fallback_timeout              â”‚
â”‚    - MESMAS messages, tools, params         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€â–º âœ… Sucesso? â†’ Retorna resposta
               â”‚
               â”œâ”€â–º âŒ Falhou?
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Tenta fallback_models[1]                 â”‚
â”‚    (se existir)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€â–º âœ… Sucesso? â†’ Retorna resposta
               â”‚
               â””â”€â–º âŒ Todos falharam â†’ Erro
```

### Importante: MemÃ³ria Preservada

**O sistema garante que**:
- âœ… As **mesmas mensagens** sÃ£o enviadas para todos os modelos
- âœ… As **mesmas tools** estÃ£o disponÃ­veis
- âœ… Os **mesmos parÃ¢metros** (temperature, top_p, max_tokens) sÃ£o usados
- âœ… A **memÃ³ria do agente** nÃ£o Ã© afetada
- âœ… As **tarefas em andamento** nÃ£o sÃ£o perdidas
- âœ… O **histÃ³rico de conversaÃ§Ã£o** permanece consistente

Isso significa que **nÃ£o hÃ¡ risco** de bagunÃ§ar o estado do agente!

---

## ğŸ” Logs e Debug

### Logs Normais (Sem Fallback)

Se o modelo primÃ¡rio funciona, vocÃª nÃ£o verÃ¡ nenhuma mensagem de fallback:

```
[INFO] Processing chat request with model: gpt-4o-mini
[INFO] Response received (250 tokens)
```

### Logs com Fallback (PrimÃ¡rio Falhou)

Quando o fallback Ã© acionado, vocÃª verÃ¡ logs detalhados:

```
[INFO] Processing chat request with model: gpt-4o
[WARN] Primary model gpt-4o failed: context deadline exceeded. Trying fallback models...
[INFO] Attempting fallback model 1/2: gpt-4o-mini
[INFO] Fallback model gpt-4o-mini succeeded!
[INFO] Response received (245 tokens)
```

### Logs com Todos os Modelos Falhando

Se nenhum modelo responder:

```
[INFO] Processing chat request with model: gpt-4o
[WARN] Primary model gpt-4o failed: context deadline exceeded. Trying fallback models...
[INFO] Attempting fallback model 1/1: gpt-4o-mini
[WARN] Fallback model gpt-4o-mini failed: API error (status 503): Service Unavailable
[ERROR] All models failed, primary error: context deadline exceeded
```

### Verificar Logs

```bash
# Tail dos logs em tempo real
tail -f .agi/agent.log | grep -i "fallback\|model"

# Ver apenas mensagens de fallback
cat .agi/agent.log | grep "fallback"
```

---

## âš¡ Ajustando o Timeout

### Timeout PadrÃ£o (30s)

```json
{
  "fallback_timeout": 30
}
```

Adequado para a maioria dos casos.

### Timeout Curto (15s)

Para respostas mais rÃ¡pidas, mas pode gerar mais fallbacks:

```json
{
  "fallback_timeout": 15
}
```

**Use quando**:
- Quer respostas rÃ¡pidas
- Tem modelos fallback muito confiÃ¡veis
- Usa modelos rÃ¡pidos como primÃ¡rio (gpt-3.5-turbo, gpt-4o-mini)

### Timeout Longo (60s)

Para modelos mais lentos ou requisiÃ§Ãµes complexas:

```json
{
  "fallback_timeout": 60
}
```

**Use quando**:
- Usa modelos grandes/lentos (GPT-4o, Claude Opus)
- RequisiÃ§Ãµes muito complexas com muitas tools
- Prefere esperar mais antes de tentar fallback

### Sem Timeout (Comportamento Antigo)

Se `fallback_models` estiver vazio, o timeout padrÃ£o do HTTP client (120s) Ã© usado:

```json
{
  "fallback_models": []
}
```

---

## ğŸ§ª Testando o Sistema

### Teste 1: Fallback ForÃ§ado (Timeout)

Configure um timeout muito curto para forÃ§ar fallback:

```json
{
  "model": "gpt-4o",
  "fallback_models": ["gpt-4o-mini"],
  "fallback_timeout": 1
}
```

Envie uma mensagem e observe os logs. O primÃ¡rio provavelmente vai timeout e o fallback serÃ¡ usado.

### Teste 2: Fallback com Modelo InvÃ¡lido

Configure um modelo invÃ¡lido como primÃ¡rio:

```json
{
  "model": "modelo-que-nao-existe",
  "fallback_models": ["gpt-4o-mini"],
  "fallback_timeout": 30
}
```

O fallback deve ser acionado imediatamente.

### Teste 3: MÃºltiplos Fallbacks

Configure 3 modelos na ordem de preferÃªncia:

```json
{
  "model": "gpt-4o",
  "fallback_models": ["gpt-4o-mini", "gpt-3.5-turbo"],
  "fallback_timeout": 20
}
```

Observe que se o primeiro e segundo falharem, o terceiro serÃ¡ tentado.

---

## ğŸ“ˆ EstatÃ­sticas de Uso

### Ver Quantas Vezes Fallback Foi Usado

```bash
# Contar acionamentos de fallback
cat .agi/agent.log | grep "Trying fallback models" | wc -l

# Ver quais modelos fallback foram bem-sucedidos
cat .agi/agent.log | grep "Fallback model .* succeeded"
```

### Taxa de Sucesso do PrimÃ¡rio

```bash
# Requests totais
cat .agi/agent.log | grep "Processing chat request" | wc -l

# Requests com fallback
cat .agi/agent.log | grep "Trying fallback" | wc -l

# Taxa de sucesso = (total - fallback) / total * 100
```

---

## ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas

### Fallback com Diferentes Timeouts

Atualmente, todos os modelos usam o mesmo timeout. Se vocÃª precisa de timeouts diferentes por modelo, considere:

1. **Timeout curto para primÃ¡rio, sem fallback**: RÃ¡pido mas menos confiÃ¡vel
2. **Timeout longo para primÃ¡rio, com fallback**: Mais confiÃ¡vel

### Fallback Entre Provedores

Para usar fallback entre provedores diferentes (ex: OpenAI â†’ Anthropic), vocÃª precisaria configurar mÃºltiplas instÃ¢ncias ou usar proxy/gateway.

**SoluÃ§Ã£o atual**: Use o mesmo provedor com modelos diferentes (recomendado).

### Custo vs Confiabilidade

Configure modelos mais caros como primÃ¡rio e mais baratos como fallback:

```json
{
  "model": "gpt-4o",              // $15/1M tokens
  "fallback_models": [
    "gpt-4o-mini",                 // $0.15/1M tokens
    "gpt-3.5-turbo"                // $0.50/1M tokens
  ]
}
```

Na maioria das vezes usa o modelo caro (alta qualidade). Quando ele falha, usa os mais baratos (economia).

---

## ğŸ› Troubleshooting

### Problema: Fallback nunca Ã© acionado

**Sintomas**:
- Configurei fallback mas logs nÃ£o mostram tentativas
- Parece que apenas o primÃ¡rio Ã© usado

**SoluÃ§Ãµes**:

1. Verifique se `fallback_models` nÃ£o estÃ¡ vazio:
   ```bash
   cat .agi/config.json | grep -A2 fallback_models
   ```

2. Verifique se o primÃ¡rio estÃ¡ funcionando bem demais (sucesso sempre):
   - Isso Ã© bom! Significa seu modelo primÃ¡rio Ã© confiÃ¡vel
   - Fallback sÃ³ aciona em falhas/timeouts

3. Aumente logs para ver tentativas:
   ```bash
   tail -f .agi/agent.log
   ```

### Problema: Fallback aciona muito frequentemente

**Sintomas**:
- Toda requisiÃ§Ã£o usa fallback
- Logs cheios de "Trying fallback models"

**SoluÃ§Ãµes**:

1. Aumente o `fallback_timeout`:
   ```json
   {
     "fallback_timeout": 60  // Era 30
   }
   ```

2. Verifique se o modelo primÃ¡rio existe e estÃ¡ acessÃ­vel:
   ```bash
   # Teste manual
   curl -X GET https://api.openai.com/v1/models \
     -H "Authorization: Bearer $API_KEY"
   ```

3. Verifique sua conexÃ£o de internet e rate limits

### Problema: Todos os modelos falhando

**Sintomas**:
- Erro: "all models failed"
- Nenhuma resposta recebida

**SoluÃ§Ãµes**:

1. Verifique API key:
   ```bash
   echo $API_KEY
   ```

2. Verifique rate limits no provedor

3. Teste manualmente cada modelo:
   ```bash
   curl -X POST https://api.openai.com/v1/chat/completions \
     -H "Authorization: Bearer $API_KEY" \
     -H "Content-Type: application/json" \
     -d '{
       "model": "gpt-4o-mini",
       "messages": [{"role": "user", "content": "test"}]
     }'
   ```

### Problema: Fallback estÃ¡ lento

**Sintomas**:
- Respostas demoram muito tempo
- MÃºltiplos timeouts antes de receber resposta

**SoluÃ§Ãµes**:

1. Reduza `fallback_timeout` para falhar mais rÃ¡pido:
   ```json
   {
     "fallback_timeout": 15  // Era 30
   }
   ```

2. Use menos modelos fallback (ex: apenas 1 ou 2)

3. Use modelos mais rÃ¡pidos:
   ```json
   {
     "model": "gpt-4o-mini",
     "fallback_models": ["gpt-3.5-turbo"]
   }
   ```

---

## ğŸ“Š Benchmarks

### LatÃªncia com Fallback

| CenÃ¡rio | Tempo MÃ©dio | ObservaÃ§Ãµes |
|---------|-------------|-------------|
| PrimÃ¡rio sucesso | 2-5s | Normal, sem overhead |
| Fallback apÃ³s timeout (30s) | 32-35s | 30s timeout + 2-5s fallback |
| Fallback apÃ³s erro imediato | 2-5s | Sem espera, direto ao fallback |
| Todos falham (2 fallbacks) | 60-65s | 3 Ã— timeout |

### RecomendaÃ§Ãµes de Timeout

| Tipo de Modelo | Timeout Recomendado |
|----------------|---------------------|
| Modelos rÃ¡pidos (gpt-3.5, mini) | 15-20s |
| Modelos mÃ©dios (gpt-4o-mini) | 30s (padrÃ£o) |
| Modelos grandes (gpt-4o, Claude) | 45-60s |
| Auto-hospedado (local LLM) | 60-120s |

---

## ğŸ¯ Best Practices

### 1. Configure Fallback para ProduÃ§Ã£o

Mesmo se seu modelo primÃ¡rio Ã© confiÃ¡vel, sempre configure pelo menos 1 fallback:

```json
{
  "model": "gpt-4o",
  "fallback_models": ["gpt-4o-mini"]
}
```

### 2. Ordem de Prioridade por Qualidade

Liste fallbacks em ordem decrescente de qualidade/capacidade:

```json
{
  "model": "gpt-4o",
  "fallback_models": [
    "gpt-4o-mini",      // Ainda muito bom
    "gpt-3.5-turbo"     // Ãšltimo recurso
  ]
}
```

### 3. Monitore Uso de Fallback

Revise logs semanalmente para identificar padrÃµes:

```bash
# RelatÃ³rio semanal
cat .agi/agent.log | grep "fallback" | tail -100
```

Se fallback estÃ¡ sendo usado muito, considere:
- Aumentar timeout
- Trocar o modelo primÃ¡rio
- Verificar problemas de conectividade

### 4. Timeout Conservador

Prefira timeouts maiores (30-45s) para evitar falsos positivos:

```json
{
  "fallback_timeout": 45
}
```

Ã‰ melhor esperar um pouco mais do que trocar de modelo desnecessariamente.

### 5. Teste Regularmente

Teste seu setup de fallback periodicamente:

```bash
# Configure timeout curto temporariamente
# Envie algumas mensagens
# Observe se fallback funciona
# Restaure timeout normal
```

---

## ğŸ”® Futuras Melhorias

PossÃ­veis funcionalidades futuras:

- [ ] Timeouts diferentes por modelo
- [ ] Fallback entre provedores (multi-provider)
- [ ] EstatÃ­sticas de uso por modelo
- [ ] Auto-ajuste de timeout baseado em latÃªncia histÃ³rica
- [ ] Circuit breaker (desabilitar modelo apÃ³s N falhas)
- [ ] Retry automÃ¡tico com backoff por modelo
- [ ] Webhooks para notificar sobre fallback

---

## ğŸ“ Exemplo Completo de ConfiguraÃ§Ã£o

```json
{
  "api_base_url": "https://api.openai.com/v1",
  "api_key": "",
  "model": "gpt-4o",
  "fallback_models": ["gpt-4o-mini", "gpt-3.5-turbo"],
  "fallback_timeout": 30,
  "temperature": 0.7,
  "max_tokens": 4000,
  "max_context_size": 128000,
  "memory": {
    "max_short_term_items": 20,
    "max_working_items": 50,
    "max_long_term_items": 100,
    "compression_trigger": 15,
    "storage_path": ".agi/memory.json"
  },
  "ui": {
    "theme": "dark",
    "show_tokens": true,
    "show_timestamp": true,
    "verbose": true
  },
  "telegram": {
    "enabled": true,
    "chat_id": 123456789,
    "notify_on_tool_start": true
  },
  "permissions": {
    "allowed_commands": ["*"],
    "allowed_tools": ["*"],
    "sensitive_tools": [
      "git_commit",
      "git_push",
      "exec_command",
      "write_file",
      "delete_file"
    ],
    "auto_approve_non_sensitive": false,
    "require_approval_for_all": false,
    "telegram_approval_timeout": 300,
    "enable_audit_log": true,
    "audit_log_path": ".agi/audit.log"
  }
}
```

---

**Status**: âœ… **PRODUCTION READY**
**Overhead**: âœ… **Zero quando nÃ£o acionado**
**Impacto na memÃ³ria**: âœ… **Nenhum - contexto preservado**

*Configure e esqueÃ§a - seu AGI estÃ¡ protegido contra falhas de modelo! ğŸ›¡ï¸*
